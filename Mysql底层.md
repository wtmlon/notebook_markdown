# MVCC多版本并发控制

解决的问题：可重复读，不能解决的问题：幻读

Mysql 默认隔离级别是<mark> REPEATABLE READ (可重复读)</mark>; 但是他存在幻读的问题；也就是读取范围记录的时候,可能有其他事物插入了数据导致读取的不一致; 具体是通过加锁（只有在写的时候才会加锁）,Next-Key Lock ：行锁和间隙锁组合起来就叫 Next-Key Lock（禁止对更新范围内进行update）。

### MVCC核心实现

InnoDB 是如何存储记录多个版本的(依靠<mark>事务版本号、行记录中的隐藏列和 Undo Log)</mark>

- 事务版本号
  
  每开启一个日志,都会从数据库中获得一个事务 ID（也称为事务版本号）,这个事务 ID 是自增的,通过 ID 大小,可以判断事务的时间顺序

- 行记录的隐藏列 （MVCC每张表都会额外创建用户看不到3个列）
  
  - row_id :隐藏的行 ID ,用来生成默认的聚集索引,如果创建数据表时没指定聚集索引,这时 InnoDB 就会用这个隐藏 ID 来创建聚集索引,采用聚集索引的方式可以提升数据的查找效率
  - trx_id: 操作这个数据事务 ID ,也就是最后一个对数据插入或者更新的事务 ID
  - roll_ptr:回滚指针,指向这个记录的 Undo Log 信息

- Undo Log  
  ![](/Users/liuting/Library/Application%20Support/marktext/images/2023-04-13-11-20-35-image.png)
  
  - InnoDB 将行记录快照保存在 Undo Log 里.
  - 数据行通过快照记录都通过链表的结构的串联了起来,每个快照都保存了 trx_id 事务 ID,如果要找到历史快照,就可以通过遍历回滚指针的方式进行查找.

- Read View:保存了当前事务开启时所有活跃的事务列表(Read View 保存了不应该让这个事务看到的其他事务 ID 列表)  （<mark>在读事务开启后第一次select便生成，以后都固定</mark>）
  ![](/Users/liuting/Library/Application%20Support/marktext/images/2023-04-13-11-24-25-image.png)
  
  - 1. trx_ids 系统当前正在活跃的事务 ID 集合
  
  - 2. low_limit_id ,活跃事务的最大的事务 ID
  
  - 3. up_limit_id 活跃的事务中最小的事务 ID
  
  - 4. creator_trx_id,创建这个 ReadView 的事务 ID
  
  - 如果当前事务的 creator_trx_id 想要读取某个行记录,这个行记录 ID 的 trx_id ,这样会有以下的情况：
    
    1. 如果 trx_id < 活跃的最小事务 ID（up_limit_id）,也就是说这个行记录在这些活跃的事务创建前就已经提交了,那么这个行记录对当前事务是可见的
    2. 如果 trx_id > 活跃的最大事务 ID（low_limit_id）,这个说明行记录在这些活跃的事务之后才创建,说明这个行记录对当前事务是不可见的
    3. 如果 up_limit_id < trx_id <low_limit_id,说明该记录需要在 trx_ids 集合中,可能还处于活跃状态,因此需要在 trx_ids 集合中遍历 ,如果 trx_id 存在于 trx_ids 集合中,证明这个事务 trx_id 还处于活跃状态,不可见,否则 ,trx_id 不存在于 trx_ids 集合中,说明事务 trx_id 已经提交了,这行记录是可见的

#### MVCC机制下查询一条记录流程

- 获取事务自己的版本号,即 事务 ID
- 获取 Read View
- 查询得到的数据,然后 Read View 中的事务版本号进行比较
- 如果不符合 ReadView 规则,<mark>那么就需要往 UndoLog 中历史快照中逐个检查符合的</mark>
- 最后返回符合规则的数据
4. innoDB 实现多版本控制 （MVCC）是通过 ReadView+ UndoLog 实现的,UndoLog 保存了历史快照,ReadView 规则帮助判断当前版本的数据是否可见

5. 可重复读跟读已提交的区别
   
   - 1. 如果事务隔离级别是<mark> 读已提交 </mark>,一个事务的每一次 Select 都会去查一次 ReadView ,每次查询的 Read View 不同,就可能会造成不可重复读或者幻读的情况
   - 2. 如果事务的隔离级别是可重读,为了避免不可重读读,一个事务只在第一次 Select 的时候会获取一次 Read View ,然后后面索引的 Select 会复用这个 ReadView

### MVCC作用

- 读写之间阻塞的问题,通过 MVCC 可以让读写互相不阻塞,读不相互阻塞,写不阻塞读,（<mark>但是写和写还是会互相阻塞的</mark>），这样可以提升数据并发处理能力

- 降低了死锁的概率,这个是因为 MVCC 采用了乐观锁的方式,读取数据时,不需要加锁,写操作,只需要锁定必要的行

- 解决了一致性读的问题,当我们朝向某个数据库在时间点的快照是,只能看到这个时间点之前事务提交更新的结果,不能看到时间点之后事务提交的更新结果

- MVCC 能不能解决幻读（根本原因是mvcc中读是快照读，而其他dml操作是当前读）
  
  不能。只要在一个事务中，第二次 select 多出了 row 就算幻读。
  
  1. a 事务先 select，b 事务 insert 确实会加一个 gap 锁，但是如果 b 事务 commit，这个 gap 锁就会释放（释放后 a 事务可以随意 dml 操作），
  2. a 事务再 select 出来的结果在 MVCC 下还和第一次 select 一样，
  3. 接着 a 事务不加条件地 update，这个 update 会作用在所有行上（包括 b 事务新加的），
  4. a 事务再次 select 就会出现 b 事务中的新行(<mark>注意此处之所以能被select出来，是因为在第三步a事务进行了update，涉及到的行事务id全是a事务id</mark>），并且这个新行已经被 update 修改了
  
  原因是前面的 UPDATE 语句执行之后，会将当前记录上存储的事务信息更新为当前的事务，而当前事务所做的任何更新，对本事务所有 SELECT 查询都变的可见，因此最后输出的结果是 UPDATE 执行后更新的所有记录。
  
  ### 快照读
  
  快照读,读取的是快照数据,不加锁的简单 Select 都属于快照读.
  
  ```mysql
  SELECT * FROM user WHERE ...
  ```
  
  ### 当前读
  
  当前读就是读的是最新数据,而不是历史的数据,加锁的 SELECT,或者对数据进行增删改都会进行当前读.
  
  ```mysql
  SELECT * FROM user LOCK IN SHARE MODE
  SELECT FROM user FOR UPDATE
  INSERT INTO user values ...
  DELETE FROM user WHERE ...
  UPDATE user SET ...
  ```

# mysql持久化，多节点同步（binlog， redolog），二阶段提交

## binlog

用于复制,在主从复制中,从库利用主库上的 binlog 进行重播,实现主从同步;用于数据库的基于时间点的还原

- 日志录入格式
  
  - 1. Statement:每一条<mark>会修改数据的 sql </mark>都会记录在 binlog 中
       1. 优点：不需要记录每一行的变化,减少了 binlog 日志量,节约了 IO,提高性能
       2. 缺点：由于记录的只是执行语句,为了这些语句能在 slave 上正确运行,因此还必须记录每条语句在执行的时候的一些相关信息（都有啥）,以保证所有语句能在 slave 得到和在 master 端执行时候相同的结果.另外 mysql 的复制,像一些特定函数功能,slave 可与 master 上要保持一致会有很多相关问题(如 sleep()函数, last_insert_id(),以及 user-defined functions(udf)会出现问题).
  
  - 2. Row:不记录 sql 语句上下文相关信息,仅保存哪条记录被修改
       1. 优点：binlog 中可以不记录执行的 sql 语句的上下文相关的信息,仅需要记录那一条记录被修改成什么了
       2. 缺点:所有的执行的语句当记录到日志中的时候,都将以每行记录的修改来记录,这样可能会<mark>产生大量的日志内容</mark>
  
  - 3. Mixedlevel:是以上两种 level 的混合使用
       
       一般的语句修改使用 statment 格式保存 binlog,statement 无法完成主从复制的操作，则采用 row 格式保存 binlog,MySQL 会根据执行的每一条具体的 sql 语句来区分对待记录的日志形式，也就是在 Statement 和 Row 之间选择一种

## redo & undo log

**InnoDB**存储引擎层的重做日志 redo log、 回滚日志 undo log

### redo log（我要把这一页设置成这样子，你记下来过会把他刷盘了）

- 用于记录事务操作的变化,记录的是数据<mark>修改之后的值,</mark>不管事务是否提交都会记录下来,在实例和介质失败（media failure）时,redo log 文件就能派上用场,如数据库掉电,InnoDB 存储引擎会使用 redo log 恢复到掉电前的时刻,以此来保证数据的完整性

- 记录的是<mark>数据页</mark>的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)

- 事务日志 REDO LOG Write Ahead Log（WAL）策略
  
  mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到<mark> Boffer Pool</mark>(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做缓冲池和磁盘之间的同步。
  
  - 如果还没来的同步的时候宕机或断电了怎么办？
  
  所以引入了 redo log 来记录已成功提交事务的修改信息，并且会把 redo log 持久化到磁盘，系统重启之后在读取 redo log 恢复最新数据。总结： redo log 是用来恢复数据的 用于保障，已提交事务的持久化特性
  
  - <mark>既然 redo log 也要刷盘 为什么不直接刷修改的数据到磁盘呢？</mark>
  
  redo_log 存储的是顺序刷盘，而修改数据的刷盘是随机 I/O； 前者更快 组提交 Group Commit，redo log 和 binlog 都具有组提交特性，在刷盘时通过等待一段时间来收集多个事务日志同时进行刷盘
  
  ### redo log 和 binlog 区别
  
  - redo log 是属于 innoDB 层面,binlog 属于 MySQL Server 层面的,这样在数据库用别的存储引擎时可以达到一致性的要求
  - redo log 是物理日志,记录该数据页更新的内容;binlog 是逻辑日志,记录的是这个更新语句的原始逻辑
  - redo log 是循环写,日志空间大小固定;binlog 是追加写,是指一份写到一定大小的时候会更换下一个文件,不会覆盖
  - binlog 可以作为恢复数据（误操作回滚）使用,主从复制搭建,redo log 作为异常宕机或者介质故障后的数据恢复使用

### Mysql的事务二阶段提交

1. Innodb 引擎 SQL 执行的 BufferPool 缓存机制  
   ![](https://files.mdnice.com/user/22315/b60f50e3-de5e-4cc0-966c-034478fb707c.png?ynotemdtimestamp=1681354772721)
   
   执行如下 sql 内部流程
   
   ```mysql
   update t set name='zhuge666' where id=1;
   ```
   
   - 执行器找引擎取 *id* 为 1 的行数据,*id* 是主键,引擎直接根据索引树拿到行数据(如果 *id* 为 1 的数据页在内存中,直接返回给执行器,否则要从磁盘中加载 *id* 为 1 所在的数据页到内存中然后返回)
   - 引擎把数据旧值写入到 *undo log* 中,便于回滚（先写undo log）
   - 执行器调用引擎接口更新引擎中的内存数据(缓存池 *buffer pool* 中)
   - 执行器调用引擎接口更新引擎中的 *redo log buffer*
   - 准备提交事务,引擎将 *redo log buffer* 的日志写入<mark>磁盘</mark>中(此时 *redo log* 处于 *prepare* 状态)
   - 准备提交事务,执行器生成这个操作的 *binlog*,并把 *binlog* 写入<mark>磁盘</mark>
   - 执行器调用引擎的提交事务接口，引擎把刚刚写入的 *redo log* 改成提交(*commit*)状态
   - 引擎中内存数据中修改的数据会通过 *IO 线程*,以 *page* 为单位随机写入磁盘（<mark>注意这里写入是要根据redo log中commit状态的log，没有这个状态的行会结合undo log回滚，所以前面先写undo log还是buffer pool都没啥影响，因为fsync之前进程崩溃的话都不会对磁盘数据有影响。</mark>）    ![](/Users/liuting/Library/Application%20Support/marktext/images/2023-04-13-12-59-46-image.png)  

# order by排序原理

- MySQL 会为每个线程分配一个内存（sort-buffer）用于排序该内存大小为 sort_buffer_size；
- 如果排序的数据量小于 sort_buffer_size，排序就会在内存中完成；
- 内部排序分为两种
- 全字段排序：到索引树上找到满足条件的主键ID根据主键ID去取出数据放到sort_buffer然后进行快速排序
- rowid排序：通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据
- 如果数据量很大，内存中无法存下这么多，就会使用磁盘临时文件来辅助排序，称为外部排序；
- 外部排序，MySQL会分为好几份单独的临时文件来存放排序后的数据，一般是磁盘文件中进行归并，然后将这些文件合并成一个大文件；

# 索引篇

### 索引的三种常见底层数据结构以及优缺点

三种常见的索引底层数据结构：分别是哈希表、有序数组和搜索树。

- 哈希表这种适用于等值查询的场景，比如 memcached 以及其它一些 NoSQL 引擎，不适合<mark>范围查询</mark>。
- 有序数组索引只适用于静态存储引擎，等值和范围查询性能好，但更新数据成本高。
- N 叉树由于读写上的性能优点以及适配磁盘访问模式以及广泛应用在数据库引擎中。
- 扩展（以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。）

### 索引的常见类型以及它是如何发挥作用的

根据叶子节点的内容，索引类型分为主键索引和非主键索引。

- 主键索引的叶子节点存的整行数据，在InnoDB里也被称为<mark>聚簇索引==主键索引</mark>。
- 非主键索引叶子节点存的主键的值，在InnoDB里也被称为二级索引。

### MyISAM 和 InnoDB 实现 B 树索引方式的区别是什么

- InnoDB 存储引擎：B+ 树索引的叶子节点保存数据本身，其数据文件本身就是索引文件（<mark>数据和索引整合在一个文件中</mark>）。
- MyISAM 存储引擎：B+ 树索引的叶子节点保存数据的物理地址，叶节点的 data 域存放的是数据记录的<mark>(物理）</mark>地址，索引文件和数据文件是分离的（数据一个文件，索引一个文件）。

### InnoDB 为什么设计 B+ 树索引

- 两个考虑因素：
  
  - InnoDB 需要执行的场景和功能需要在特定查询上拥有较强的性能。
  - CPU 将磁盘上的数据加载到内存中需要花费大量时间。

- 为什么选择 B+ 树：
  
  - 哈希索引虽然能提供O（1）复杂度查询，但对范围查询和排序却无法很好的支持，最终会导致全表扫描。
  
  - B 树能够在非叶子节点存储数据，但会导致在查询连续数据可能带来更多的随机 IO。
  
  - 而 B+ 树的所有叶节点可以通过指针来相互连接，减少顺序遍历带来的随机 IO。
  
  - 普通索引还是唯一索引？
    
    由于唯一索引用不上 change buffer 的优化机制（每次修改要<mark>立马</mark>判断是否出现重复值来维护唯一性，那么change buffer 这种<mark>懒更新</mark>手段就不能施行），因此如果业务可以接受，从性能角度出发建议你优先考虑非唯一索引。
    
    ### MySQL 的 change buffer 是什么
    
    - 当需要更新一个数据页时，如果数据页在内存中就直接更新；而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中。
    - 这样就不需要从磁盘中读入这个数据页了，在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
    - 注意唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。
    - 适用场景（<mark>多写少查</mark>）：
      - 对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
      - 反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。

### 什么是覆盖索引和索引下推

- 覆盖索引：
  
  - 在某个查询里面，索引 k 已经“覆盖了”我们的查询需求，称为覆盖索引。
  - 覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

- 索引下推：
  
  - MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，<mark>直接过滤掉不满足条件的记录</mark>，减少回表次数。

### 哪些操作会导致索引失效

- 对索引使用左或者左右模糊匹配，也就是 like %xx 或者 like %xx% 这两种方式都会造成索引失效。原因在于查询的结果可能是多个，不知道从哪个索引值开始比较，于是就只能通过全表扫描的方式来查询。
- 对索引进行函数/对索引进行表达式计算，因为索引保持的是索引字段的原始值，而不是经过函数计算的值，自然就没办法走索引, 例如：
  
  ```sql
  select * from table where age + 1 = 16;
  ```
- 对索引进行隐式转换相当于使用了新函数。
- WHERE 子句中的 OR语句，只要<mark>有条件列不是索引列，就会进行全表扫描</mark>。

### 如何给字符串加索引

- 直接创建完整索引，这样可能会比较占用空间。
- 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引。
- 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题。
- 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。
