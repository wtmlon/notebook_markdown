# 相对位置编码

## Transformers论文中所用

 基于三角函数

$$
sin(a+b) = sinacosb + sinbcosa

$$

可将a和b位置编码推广到a+b位置，实现相对编码。

## 经典式（拆解attention公式，替换进需要学习的位置编码矩阵Rij, 因为有截断，既超过最大最小长度取默认最大最小），所以可以拓展到无限长度。

![](/Users/liuting/Library/Application%20Support/marktext/images/2023-04-05-13-05-53-image.png)

## XLNET式

![](/Users/liuting/Library/Application%20Support/marktext/images/2023-04-05-13-18-51-image.png)

## T5式，改公式，分桶截断。

![](/Users/liuting/Library/Application%20Support/marktext/images/2023-04-05-13-19-37-image.png)

# 绝对位置编码

BERT，GPT：训练一个512 * 768的矩阵向量，直接叠加。


